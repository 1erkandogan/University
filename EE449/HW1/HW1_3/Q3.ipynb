{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import json\n",
    "\n",
    "from utils import visualizeWeights\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_1(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(mlp_1, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = torch.nn.Linear(input_size, 32)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class mlp_2(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(mlp_2, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = torch.nn.Linear(input_size, 32)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(32, 64, bias=False)\n",
    "        self.fc3 = torch.nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class cnn_3(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(cnn_3, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 3, padding = 'valid')\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 16, out_channels = 8, kernel_size = 5, padding = 'valid')\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 7, padding = 'valid')\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = torch.nn.Linear(16 * 3 * 3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class cnn_4(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(cnn_4, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 3, padding = 'valid')\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 16, out_channels = 8, kernel_size = 3, padding = 'valid')\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 5, padding = 'valid')\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 5, padding = 'valid')\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc = torch.nn.Linear(16 * 4 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class cnn_5(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(cnn_5, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 3, padding = 'valid')\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding = 'valid')\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels = 16, out_channels = 8, kernel_size = 3, padding = 'valid')\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding = 'valid')\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv5 = torch.nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 3, padding = 'valid')\n",
    "        self.relu5 = torch.nn.ReLU()\n",
    "        self.conv6 = torch.nn.Conv2d(in_channels = 16, out_channels = 8, kernel_size = 3, padding = 'valid')\n",
    "        self.relu6 = torch.nn.ReLU()\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc = torch.nn.Linear(8 * 4 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n",
      "True\n",
      "0\n",
      "<torch.cuda.device object at 0x000001DD7EBB1F90>\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"{device} is available\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Training set has 45000 instances\n",
      "Test set has 10000 instances\n",
      "Validation set has 5000 instances\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    torchvision.transforms.Grayscale()\n",
    "])\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 3\n",
    "NUM_STEPS = 1\n",
    "LEARNING_RATE = 0.01\n",
    "# training set\n",
    "trainset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "#indices = np.arange(len(trainset))\n",
    "#train_indices, test_indices = train_test_split(indices, test_size=0.1, stratify=trainset.targets, random_state=42)\n",
    "#trainset = torch.utils.data.Subset(trainset, train_indices)\n",
    "#valset = torch.utils.data.Subset(trainset, test_indices)\n",
    "trainset, valset = train_test_split(trainset, test_size=0.1, random_state=42)\n",
    "testset = torchvision.datasets.CIFAR10('./data', train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE*100, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('Training set has {} instances'.format(len(trainset)))\n",
    "print('Test set has {} instances'.format(len(testset)))\n",
    "print('Validation set has {} instances'.format(len(valset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model_, outputs_, labels_, loss_,step_train_loss_, step_train_acc_, step_val_acc_):\n",
    "    model_.eval()\n",
    "\n",
    "    _, predicted = torch.max(outputs_.data, 1)\n",
    "    n_samples = labels_.size(0)\n",
    "    n_correct = (predicted == labels_).sum().item()\n",
    "    \n",
    "    training_acc = 100.0 * n_correct / n_samples\n",
    "    val_loss = loss_.item()\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    for i, val_data in enumerate(valloader, 0):\n",
    "        val_inputs, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "        \n",
    "        val_outputs = model_(val_inputs)\n",
    "        \n",
    "        _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "        val_total += val_labels.size(0)\n",
    "        val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "    step_train_loss_.append(val_loss)\n",
    "    step_train_acc_.append(training_acc)\n",
    "    step_val_acc_.append(val_acc)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, step_test_acc_, best_weight_, best_acc_):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        \n",
    "#        n_class_correct = [0 for i in range(10)]\n",
    "#        n_class_samples = [0 for i in range(10)]\n",
    "\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "#            for i in range(BATCH_SIZE):\n",
    "#                label = labels[i]\n",
    "#                pred = predicted[i]\n",
    "#                if (label == pred):\n",
    "#                    n_class_correct[label] += 1\n",
    "#                n_class_samples[label] += 1\n",
    "\n",
    "        test_acc = 100.0 * n_correct / n_samples\n",
    "        step_test_acc_.append(test_acc)\n",
    "        \n",
    "        if(test_acc > best_acc_):\n",
    "            best_acc_ = test_acc\n",
    "            model.to('cpu')\n",
    "            if (model.__class__.__name__ == 'mlp_1' or model.__class__.__name__ == 'mlp_2'):\n",
    "                best_weight_ = model.fc1.weight.data.numpy()\n",
    "            else:\n",
    "                best_weight_ = model.conv1.weight.data.numpy()\n",
    "            model.to(device)\n",
    "\n",
    "        #print(f'Accuracy of the network on the test images: {test_acc} %')\n",
    "        #for i in range(10):\n",
    "            #class_acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            #print(f'Accuracy of {classes[i]}: {class_acc} %')\n",
    "\n",
    "    return best_weight_, best_acc_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_, optimizer_fn, loss_fn, step_train_loss_, step_train_acc_, step_val_acc_,epoch_,step_):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        model_.train()\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model_(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer_fn.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_fn.step()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            val(model_, outputs, labels, loss, step_train_loss_, step_train_acc_, step_val_acc_)\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw3_1():\n",
    "    model_mlp1 = mlp_1(1024, 10).to(device)\n",
    "    model_mlp2 = mlp_2(1024, 10).to(device)\n",
    "    model_cnn3 = cnn_3(10).to(device)\n",
    "    model_cnn4 = cnn_4(10).to(device)\n",
    "    model_cnn5 = cnn_5(10).to(device)\n",
    "    \n",
    "    models = [model_mlp1, model_mlp2, model_cnn3, model_cnn4, model_cnn5]\n",
    "    models = [model_cnn5]\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "        model_train_loss = []\n",
    "        model_train_acc = []\n",
    "        model_val_acc = []\n",
    "        best_weight = 0\n",
    "        best_acc = 0\n",
    "\n",
    "        for step in range(NUM_STEPS):\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "            step_train_loss = []\n",
    "            step_train_acc = []\n",
    "            step_val_acc = []\n",
    "            step_test_acc = []\n",
    "\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                print(f'Epoch {epoch+1}/{NUM_EPOCHS}  {step+1}/{NUM_STEPS} for {model_name} model')\n",
    "                train(model, optimizer, criterion, step_train_loss, step_train_acc, step_val_acc, epoch, step)\n",
    "\n",
    "            model_train_loss.append(step_train_loss)\n",
    "            model_train_acc.append(step_train_acc)\n",
    "            model_val_acc.append(step_val_acc)\n",
    "            print(f\"step_train_loss: {step_train_loss}, step_train_acc: {step_train_acc}, step_val_acc: {step_val_acc}\")\n",
    "            best_weight, best_acc = test(model, step_test_acc, best_weight, best_acc)\n",
    "\n",
    "        avg_train_loss = [sum(x)/len(x) for x in zip(*model_train_loss)]\n",
    "        avg_train_acc = [sum(x)/len(x) for x in zip(*model_train_acc)]\n",
    "        avg_valid_acc = [sum(x)/len(x) for x in zip(*model_val_acc)]\n",
    "        model_result = {\n",
    "            'name': model_name,\n",
    "            'loss_curve': avg_train_loss,\n",
    "            'train_acc_curve': avg_train_acc,\n",
    "            'val_acc_curve': avg_valid_acc,\n",
    "            'test_acc': best_acc,\n",
    "            'weights': best_weight.tolist(),\n",
    "        }\n",
    "\n",
    "        with open(\"q2_\"+model_name+\".json\", \"w\") as outfile:\n",
    "            json.dump(model_result, outfile)\n",
    "\n",
    "        visualizeWeights(best_weight, save_dir='Q3', filename='input_weights_'+model_name)\n",
    "\n",
    "    print(\"Training Done\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw3_1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
